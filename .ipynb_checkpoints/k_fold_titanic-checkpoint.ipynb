{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the two datasets\n",
    "df_train = pd.read_csv(\"Titanic_datasets/train.csv\")\n",
    "df_test = pd.read_csv(\"Titanic_datasets/test.csv\")\n",
    "# Menggabungkan df_train dan df_test ke dfmerged\n",
    "df = pd.concat([df_train, df_test], sort = False)\n",
    "df.reset_index(drop = False, inplace = True)\n",
    "df.to_csv(\"Titanic_datasets/dftitanic.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  PassengerId  Survived  Pclass  \\\n",
       "0      0            1       0.0       3   \n",
       "1      1            2       1.0       1   \n",
       "2      2            3       1.0       3   \n",
       "3      3            4       1.0       1   \n",
       "4      4            5       0.0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Titanic_datasets/dftitanic.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index             0\n",
       "PassengerId       0\n",
       "Survived        418\n",
       "Pclass            0\n",
       "Name              0\n",
       "Sex               0\n",
       "Age             263\n",
       "SibSp             0\n",
       "Parch             0\n",
       "Ticket            0\n",
       "Fare              1\n",
       "Cabin          1014\n",
       "Embarked          2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index       | 0.00%\n",
      "PassengerId | 0.00%\n",
      "Survived    | 31.93%\n",
      "Pclass      | 0.00%\n",
      "Name        | 0.00%\n",
      "Sex         | 0.00%\n",
      "Age         | 20.09%\n",
      "SibSp       | 0.00%\n",
      "Parch       | 0.00%\n",
      "Ticket      | 0.00%\n",
      "Fare        | 0.08%\n",
      "Cabin       | 77.46%\n",
      "Embarked    | 0.15%\n"
     ]
    }
   ],
   "source": [
    "def missing_values_report(df):\n",
    "\tfor index, missing in enumerate(df.isna().sum()):\n",
    "\t\tprint(f\"{df.columns[index]:11} | {missing * 100 / len(df):.2f}%\")\n",
    "\n",
    "missing_values_report(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1309 entries, 0 to 1308\n",
      "Data columns (total 13 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   index        1309 non-null   int64  \n",
      " 1   PassengerId  1309 non-null   int64  \n",
      " 2   Survived     891 non-null    float64\n",
      " 3   Pclass       1309 non-null   int64  \n",
      " 4   Name         1309 non-null   object \n",
      " 5   Sex          1309 non-null   object \n",
      " 6   Age          1046 non-null   float64\n",
      " 7   SibSp        1309 non-null   int64  \n",
      " 8   Parch        1309 non-null   int64  \n",
      " 9   Ticket       1309 non-null   object \n",
      " 10  Fare         1308 non-null   float64\n",
      " 11  Cabin        295 non-null    object \n",
      " 12  Embarked     1307 non-null   object \n",
      "dtypes: float64(3), int64(5), object(5)\n",
      "memory usage: 133.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['Survived', 'Embarked'], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Cabin'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index       | 0.00%\n",
      "PassengerId | 0.00%\n",
      "Survived    | 0.00%\n",
      "Pclass      | 0.00%\n",
      "Name        | 0.00%\n",
      "Sex         | 0.00%\n",
      "Age         | 19.91%\n",
      "SibSp       | 0.00%\n",
      "Parch       | 0.00%\n",
      "Ticket      | 0.00%\n",
      "Fare        | 0.00%\n",
      "Embarked    | 0.00%\n"
     ]
    }
   ],
   "source": [
    "missing_values_report(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isi age berdasarkan mean dari keseluruhan age\n",
    "# df['Age'].fillna(df['Age'].mean(skipna=True), inplace=True) # Gunakan mean karena data numerik\n",
    "# Isi age berdasarkan Survived\n",
    "df['Age'] = df.groupby('Survived')['Age'].transform(lambda x: x.fillna(x.mean())).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index       | 0.00%\n",
      "PassengerId | 0.00%\n",
      "Survived    | 0.00%\n",
      "Pclass      | 0.00%\n",
      "Name        | 0.00%\n",
      "Sex         | 0.00%\n",
      "Age         | 0.00%\n",
      "SibSp       | 0.00%\n",
      "Parch       | 0.00%\n",
      "Ticket      | 0.00%\n",
      "Fare        | 0.00%\n",
      "Embarked    | 0.00%\n"
     ]
    }
   ],
   "source": [
    "missing_values_report(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 889 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   index        889 non-null    int64  \n",
      " 1   PassengerId  889 non-null    int64  \n",
      " 2   Survived     889 non-null    float64\n",
      " 3   Pclass       889 non-null    int64  \n",
      " 4   Name         889 non-null    object \n",
      " 5   Sex          889 non-null    object \n",
      " 6   Age          889 non-null    float64\n",
      " 7   SibSp        889 non-null    int64  \n",
      " 8   Parch        889 non-null    int64  \n",
      " 9   Ticket       889 non-null    object \n",
      " 10  Fare         889 non-null    float64\n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(3), int64(5), object(4)\n",
      "memory usage: 90.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embarked\n",
      "S    644\n",
      "C    168\n",
      "Q     77\n",
      "Name: count, dtype: int64\n",
      "Mode: S\n"
     ]
    }
   ],
   "source": [
    "print(df['Embarked'].value_counts())\n",
    "\n",
    "mode = df['Embarked'].value_counts().idxmax()\n",
    "print(f\"Mode: {mode}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived\n",
       "0.0    549\n",
       "1.0    340\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Survived'].value_counts() # Data imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Encoding (Target Encoder for Embarked)\n",
    "# remove text columns and the PassengerId\n",
    "df = df.drop(['Name', 'Ticket', 'PassengerId'], axis=1)\n",
    "# Turn the 'Sex' feature into binary using label encoder\n",
    "label_encoder = LabelEncoder()\n",
    "df['Sex'] = label_encoder.fit_transform(df['Sex'])\n",
    "# One hot encode the Embarked feature\n",
    "df = pd.get_dummies(df, columns=['Embarked'], dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  Survived  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked_C  \\\n",
       "0      0       0.0       3    1  22.0      1      0   7.2500           0   \n",
       "1      1       1.0       1    0  38.0      1      0  71.2833           1   \n",
       "2      2       1.0       3    0  26.0      0      0   7.9250           0   \n",
       "3      3       1.0       1    0  35.0      1      0  53.1000           0   \n",
       "4      4       0.0       3    1  35.0      0      0   8.0500           0   \n",
       "\n",
       "   Embarked_Q  Embarked_S  \n",
       "0           0           1  \n",
       "1           0           0  \n",
       "2           0           1  \n",
       "3           0           1  \n",
       "4           0           1  "
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export file yang sudah bersih\n",
    "df.to_csv(\"Titanic_datasets/dfclean.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the data using StandarScaler -> mean = 0, std = 1 -> value range [-1, 1]\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X = df.drop(['Survived'], axis=1)\n",
    "y = df['Survived']\n",
    "\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test =  train_test_split(X, y,random_state = 100, test_size = 0.2)\n",
    "# print(X_train.shape)\n",
    "# print(X_test.shape)\n",
    "# print(y_train.shape)\n",
    "# print(y_test.shape)\n",
    "\n",
    "# Oversampling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(random_state=2)\n",
    "X_train,y_train = sm.fit_resample(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate the error values\n",
    "#MSE, RMSE, and R-squared\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def error_values(): \n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print('Mean Squared Error: ', mse)\n",
    "    print('Root Mean Squared Error: ', rmse)\n",
    "    print('R-squared: ', r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8258426966292135\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.85      0.86       114\n",
      "         1.0       0.75      0.78      0.76        64\n",
      "\n",
      "    accuracy                           0.83       178\n",
      "   macro avg       0.81      0.82      0.81       178\n",
      "weighted avg       0.83      0.83      0.83       178\n",
      "\n",
      "Confusion Matrix: \n",
      " [[97 17]\n",
      " [14 50]]\n",
      "Mean Squared Error:  0.17415730337078653\n",
      "Root Mean Squared Error:  0.4173215826802953\n",
      "R-squared:  0.24369517543859653\n"
     ]
    }
   ],
   "source": [
    "# Implement Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Decision Tree\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred = dt.predict(X_test)\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('Classification Report: \\n', classification_report(y_test, y_pred))\n",
    "print('Confusion Matrix: \\n', confusion_matrix(y_test, y_pred))\n",
    "\n",
    "error_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8089887640449438\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.83      0.85       114\n",
      "         1.0       0.72      0.77      0.74        64\n",
      "\n",
      "    accuracy                           0.81       178\n",
      "   macro avg       0.79      0.80      0.80       178\n",
      "weighted avg       0.81      0.81      0.81       178\n",
      "\n",
      "Confusion Matrix: \n",
      " [[95 19]\n",
      " [15 49]]\n",
      "Mean Squared Error:  0.19101123595505617\n",
      "Root Mean Squared Error:  0.4370483222197017\n",
      "R-squared:  0.17050438596491224\n"
     ]
    }
   ],
   "source": [
    "# Implement KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('Classification Report: \\n', classification_report(y_test, y_pred))\n",
    "print('Confusion Matrix: \\n', confusion_matrix(y_test, y_pred))\n",
    "\n",
    "error_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8033707865168539\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.84      0.85       114\n",
      "         1.0       0.72      0.73      0.73        64\n",
      "\n",
      "    accuracy                           0.80       178\n",
      "   macro avg       0.79      0.79      0.79       178\n",
      "weighted avg       0.80      0.80      0.80       178\n",
      "\n",
      "Confusion Matrix: \n",
      " [[96 18]\n",
      " [17 47]]\n",
      "Mean Squared Error:  0.19662921348314608\n",
      "Root Mean Squared Error:  0.4434289272060925\n",
      "R-squared:  0.14610745614035092\n"
     ]
    }
   ],
   "source": [
    "# Implement Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('Classification Report: \\n', classification_report(y_test, y_pred))\n",
    "print('Confusion Matrix: \\n', confusion_matrix(y_test, y_pred))\n",
    "\n",
    "error_values()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
